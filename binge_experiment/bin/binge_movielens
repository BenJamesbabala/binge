#!/usr/bin/env python
import click

import numpy as np

import pandas as pd

from scipy.stats import distributions

from sklearn.model_selection import ParameterSampler

from binge import FactorizationModel
from binge.data import movielens
from binge.evaluation import mrr_score

from binge_experiment.results import Results


def random_search(train,
                  test,
                  validation,
                  xnor,
                  embedding_dim,
                  cuda=True,
                  iterations=10,
                  minibatch_size=4096,
                  random_state=None,
                  verbose=False):

    results_db = Results('movielens_100k.log')

    space = {
        'n_iter': distributions.randint(5, 50),
        'batch_size': [64, 128, 256, 1024, 2048, 4096],
        'l2': [0.0],
        'learning_rate': [1e-3],
        # 'l2': distributions.expon(0, 0.005),
        # 'learning_rate': distributions.expon(0, 0.005),
        'loss': ['bpr', 'adaptive']  # TODO: re-enable adaptive loss
    }

    sampler = ParameterSampler(space,
                               n_iter=iterations,
                               random_state=random_state)

    with click.progressbar(sampler,
                           length=iterations,
                           label='Optimizing hyperparameters for dim={}'.format(
                               embedding_dim)) as bar:
        for hyperparam_set in bar:
            model = FactorizationModel(xnor=xnor,
                                       use_cuda=cuda,
                                       embedding_dim=embedding_dim,
                                       random_seed=random_state,
                                       **hyperparam_set)

            if model.get_params() in results_db:
                continue

            model.fit(train)
            mrr = mrr_score(model, test, train + validation)

            if verbose:
                print('Hyperparams {}, score {}'.format(model.get_params(),
                                                        mrr.mean()))

            results_db.save(model.get_params(), mrr)


@click.group()
@click.pass_context
@click.option('--random-seed', default=420)
@click.option('--gpu', is_flag=True, help='Use the GPU')
@click.option('--xnor/--no-xnor', default=False)
@click.option('--verbose', is_flag=True)
def cli(ctx, xnor, gpu, random_seed, verbose):

    ctx.obj['options'] = (xnor, gpu, random_seed, verbose)


@cli.command()
@click.pass_context
def check(ctx):

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens(
        random_seed=random_seed
    )

    batch_size = 128
    n_iter = 10
    embedding_dim = 64

    model = FactorizationModel(embedding_dim=embedding_dim,
                               batch_size=batch_size,
                               n_iter=n_iter,
                               random_seed=random_seed,
                               loss='bpr')
    model.fit(train, verbose=verbose)

    validation_mrrs = mrr_score(model, validation, train + test)

    print('Validation MRR for bpr: {}'
          .format(validation_mrrs.mean()))

    model = FactorizationModel(embedding_dim=embedding_dim,
                               batch_size=batch_size,
                               n_iter=n_iter,
                               loss='adaptive')
    model.fit(train, verbose=verbose)

    validation_mrrs = mrr_score(model, validation, train + test)

    print('Validation MRR for adaptive: {}'
          .format(validation_mrrs.mean()))


@cli.command()
@click.pass_context
@click.option('--num-iterations', default=10,
              help='Number of hyperparam search iterations')
def optimize(ctx, num_iterations=10):

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens(
        random_seed=random_seed
    )

    for embedding_dim in (32, 64, 128, 256, 512, 1024, 2048, 4096):
        random_search(train,
                      test,
                      validation,
                      xnor,
                      embedding_dim=embedding_dim,
                      iterations=num_iterations,
                      cuda=gpu,
                      random_state=random_seed,
                      verbose=verbose)


@cli.command()
@click.pass_context
def validate(ctx):

    results_db = Results('movielens_100k.log')
    validation_db = Results('movielens_100k_validation.log')

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens(
        random_seed=random_seed
    )

    with click.progressbar((32, 64, 128, 256, 512, 1024, 2048, 4096),
                           label='Running validation') as bar:
        for embedding_dim in bar:
            hyperparams = results_db.load_best(embedding_dim, xnor)

            if verbose:
                print('Validating hyperparams {}'.format(hyperparams))

            if hyperparams in validation_db:
                continue

            model = FactorizationModel(**hyperparams)
            model.fit(train, verbose=verbose)

            validation_mrrs = mrr_score(model, validation, train + test)
            scorer_validation_mrrs = mrr_score(model.get_scorer(),
                                               validation,
                                               train + test)

            validation_db.save(model.get_params(), validation_mrrs)

            if verbose:
                print('Validation MRR: {} ({} from scorer)'
                      .format(validation_mrrs.mean(),
                              scorer_validation_mrrs.mean()))


@cli.command()
def show():

    hyperparam_headers = ('embedding_dim', 'xnor', 'mean_mrr',
                          'loss', 'n_iter', 'batch_size', 'l2', 'learning_rate')
    validation_headers = ('embedding_dim', 'xnor', 'mean_mrr', 'duration', 'qpms', 'memory')

    hyperparams_db = Results('movielens_100k.log')
    validation_db = Results('movielens_100k_validation.log')

    print('Hyperparameters')
    print(hyperparams_db.load()
          .to_string(columns=hyperparam_headers))
    print('Validation')
    print(validation_db.load()
          .to_string(columns=validation_headers))


    data = validation_db.load()

    float_results = data[data['xnor'] == 0]
    binary_results = data[data['xnor'] == 1]

    column_data = [float_results['embedding_dim'].values,
                   float_results['mean_mrr'].values,
                   binary_results['mean_mrr'].values,
                   (binary_results['mean_mrr'].values
                    / float_results['mean_mrr'].values),
                   float_results['qpms'].values,
                   binary_results['qpms'].values,
                   (binary_results['qpms'].values
                    / float_results['qpms'].values),
                   float_results['memory'].values,
                   binary_results['memory'].values,
                   (binary_results['memory'].values
                    / float_results['memory'].values)]
    column_names = ['Dimension',
                    'MRR',
                    'Binary MRR',
                    'MRR ratio',
                    'QPMS',
                    'Binary QPMS',
                    'QPMS ratio',
                    'Memory use',
                    'Binary memory use',
                    'Memory use ratio']
    pretty = pd.DataFrame.from_items(zip(column_names, column_data))

    print(pretty.to_string())

    highest_float_mrr_row = pretty.iloc[[np.argmax(pretty['MRR'].values)]].to_dict('records')[0]
    highest_binary_mrr_row = pretty.iloc[[np.argmax(pretty['Binary MRR'].values)]].to_dict('records')[0]

    fastest_float_row = pretty.iloc[[np.argmax(pretty['QPMS'].values)]].to_dict('records')[0]
    equally_fast_binary = pretty[pretty['Binary QPMS'] > fastest_float_row['QPMS']]
    fast_binary_row = equally_fast_binary.iloc[[np.argmax(equally_fast_binary['Binary MRR'].values)]].to_dict('records')[0]

    print('When optimizing for MRR in both settings (at {} dimensions for the '
          'continuous and {} for the binary case), the XNOR representation achieves {:.0f}% of the maximum MRR of the float '
          'representations at {:.1f} times the query throughput and using only '
          '{:.0f}% of the memory.'.format(
              int(highest_float_mrr_row['Dimension']),
              int(highest_binary_mrr_row['Dimension']),
              highest_binary_mrr_row['Binary MRR'] / highest_float_mrr_row['MRR'] * 100,
              highest_binary_mrr_row['Binary QPMS'] / highest_float_mrr_row['QPMS'],
              highest_binary_mrr_row['Binary memory use'] / highest_float_mrr_row['Memory use'] * 100,
          ))
    print('When optimizing for query throughput at {} dimensions for '
          'the continuous case, the XNOR representation (at {} dimensions) '
          'can improve the ranking performance by achieving {:.0f}% '
          'of the continuous MRR while being slightly faster at {:.1f} times '
          'the query throughput, and using {:.0f}% of the memory.'.format(
              int(fastest_float_row['Dimension']),
              int(fast_binary_row['Dimension']),
              fast_binary_row['Binary MRR'] / fastest_float_row['MRR'] * 100,
              fast_binary_row['Binary QPMS'] / fastest_float_row['QPMS'],
              fast_binary_row['Binary memory use'] / fastest_float_row['Memory use'] * 100
          ))


@cli.command()
def plot():

    validation_db = Results('movielens_100k_validation.log')
    validation_db.plot('movielens.svg')


if __name__ == '__main__':
    cli(obj={})
