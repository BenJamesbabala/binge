#!/usr/bin/env python
import click

import numpy as np

import pandas as pd

from scipy.stats import distributions

from sklearn.model_selection import ParameterSampler

from binge import FactorizationModel, PopularityModel
from binge.data import movielens
from binge.evaluation import mrr_score

from binge_experiment.results import Results

EMBEDDING_DIMENSIONS = (32, 64, 128, 256, 512, 1024, 2048)#, 4096) 


def random_search(train,
                  test,
                  validation,
                  xnor,
                  embedding_dim,
                  cuda=True,
                  iterations=10,
                  minibatch_size=4096,
                  random_state=None,
                  verbose=False):

    results_db = Results('movielens_1M.log')

    space = {
        'n_iter': distributions.randint(5, 30),
        'batch_size': [2048, 4096, 8192],
        'l2': [1e-6, 1e-4, 0.0],
        'learning_rate': [1e-3, 1e-2, 5 * 1e-2],
        # 'l2': distributions.expon(0, 0.005),
        # 'learning_rate': distributions.expon(0, 0.005),
        'loss': ['bpr', 'adaptive']  # TODO: re-enable adaptive loss
    }

    sampler = ParameterSampler(space,
                               n_iter=iterations,
                               random_state=random_state)

    with click.progressbar(sampler,
                           length=iterations,
                           label='Optimizing hyperparameters for dim={}'.format(
                               embedding_dim)) as bar:
        for hyperparam_set in bar:
            model = FactorizationModel(xnor=xnor,
                                       use_cuda=cuda,
                                       embedding_dim=embedding_dim,
                                       random_seed=random_state,
                                       **hyperparam_set)

            if model.get_params() in results_db:
                continue

            model.fit(train)
            mrr = mrr_score(model, test, train + validation)

            if verbose:
                print('Hyperparams {}, score {}'.format(model.get_params(),
                                                        mrr.mean()))

            results_db.save(model.get_params(), mrr)


@click.group()
@click.pass_context
@click.option('--random-seed', default=420)
@click.option('--gpu', is_flag=True, help='Use the GPU')
@click.option('--xnor/--no-xnor', default=False)
@click.option('--verbose', is_flag=True)
def cli(ctx, xnor, gpu, random_seed, verbose):

    ctx.obj['options'] = (xnor, gpu, random_seed, verbose)


@cli.command()
@click.pass_context
def check(ctx):

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens_1M(
        random_seed=random_seed
    )

    batch_size = 128
    n_iter = 10
    embedding_dim = 64

    model = FactorizationModel(embedding_dim=embedding_dim,
                               batch_size=batch_size,
                               n_iter=n_iter,
                               random_seed=random_seed,
                               loss='bpr')
    model.fit(train, verbose=verbose)

    validation_mrrs = mrr_score(model, validation, train + test)

    print('Validation MRR for bpr: {}'
          .format(validation_mrrs.mean()))

    model = FactorizationModel(embedding_dim=embedding_dim,
                               batch_size=batch_size,
                               n_iter=n_iter,
                               loss='adaptive')
    model.fit(train, verbose=verbose)

    validation_mrrs = mrr_score(model, validation, train + test)

    print('Validation MRR for adaptive: {}'
          .format(validation_mrrs.mean()))


@cli.command()
@click.pass_context
@click.option('--num-iterations', default=10,
              help='Number of hyperparam search iterations')
def optimize(ctx, num_iterations=10):

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens_1M(
        random_seed=random_seed
    )

    for embedding_dim in EMBEDDING_DIMENSIONS:
        random_search(train,
                      test,
                      validation,
                      xnor,
                      embedding_dim=embedding_dim,
                      iterations=num_iterations,
                      cuda=gpu,
                      random_state=random_seed,
                      verbose=verbose)


@cli.command()
@click.pass_context
def validate(ctx):

    results_db = Results('movielens_1M.log')
    validation_db = Results('movielens_1M_validation.log')

    (xnor, gpu, random_seed, verbose) = ctx.obj['options']

    train, test, validation = movielens.fetch_movielens_1M(
        random_seed=random_seed
    )

    popularity_model = PopularityModel()
    popularity_model.fit(train)

    popularity_mrr = mrr_score(popularity_model,
                               validation,
                               train + test)
    print('Popularity MRR: {}'.format(popularity_mrr.mean()))

    with click.progressbar(EMBEDDING_DIMENSIONS,
                           label='Running validation') as bar:
        for embedding_dim in bar:
            hyperparams = results_db.load_best(embedding_dim, xnor)

            if verbose:
                print('Validating hyperparams {}'.format(hyperparams))

            if hyperparams in validation_db:
                continue

            model = FactorizationModel(**hyperparams)
            model.fit(train, verbose=verbose)

            validation_mrrs = mrr_score(model, validation, train + test)

            validation_db.save(model.get_params(), validation_mrrs)

            if verbose:
                print('Validation MRR: {}'
                      .format(validation_mrrs.mean()))


@cli.command()
def show():

    hyperparam_headers = ('embedding_dim', 'xnor', 'mean_mrr',
                          'loss', 'n_iter', 'batch_size', 'l2', 'learning_rate')
    validation_headers = ('embedding_dim', 'xnor', 'mean_mrr', 'duration', 'qpms', 'memory')

    hyperparams_db = Results('movielens_1M.log')
    validation_db = Results('movielens_1M_validation.log')

    print('Hyperparameters')
    print(hyperparams_db.load()
          .to_string(columns=hyperparam_headers))
    print('Validation')
    print(validation_db.load()
          .to_string(columns=validation_headers))


    data = validation_db.load()

    float_results = data[data['xnor'] == 0]
    binary_results = data[data['xnor'] == 1]

    column_data = [float_results['embedding_dim'].values,
                   float_results['mean_mrr'].values,
                   binary_results['mean_mrr'].values,
                   (binary_results['mean_mrr'].values
                    / float_results['mean_mrr'].values),
                   float_results['qpms'].values.astype(np.int64),
                   binary_results['qpms'].values.astype(np.int64),
                   (binary_results['qpms'].values
                    / float_results['qpms'].values),
                   float_results['memory'].values,
                   binary_results['memory'].values,
                   (binary_results['memory'].values
                    / float_results['memory'].values)]
    column_names = ['Dimension',
                    'MRR',
                    'Binary MRR',
                    'MRR ratio',
                    'PPMS',
                    'Binary PPMS',
                    'PPMS ratio',
                    'Memory use',
                    'Binary memory use',
                    'Memory use ratio']
    pretty = pd.DataFrame.from_items(zip(column_names, column_data))

    def fmt(x):

        if isinstance(x, (int, np.int64, np.int32)):
            if x > 10000:
                fmt_string = "{:,}"
            else:
                fmt_string = "{}"
        else:
            fmt_string = "{:.3f}"

        return fmt_string.format(x)
    
    print(pretty.to_string())
    print(pretty[['Dimension',
                  'MRR',
                  'Binary MRR',
                  'MRR ratio',
                  'PPMS',
                  'Binary PPMS',
                  'PPMS ratio',
                  'Memory use ratio']]
          .to_latex(index=False,
                    formatters=[fmt] * 8
                    ))

    highest_float_mrr_row = (pretty.iloc[[np.argmax(pretty['MRR'].values)]]
                             .to_dict('records')[0])
    highest_binary_mrr_row = (pretty.iloc[[np.argmax(pretty['Binary MRR'].values)]]
                              .to_dict('records')[0])

    fastest_float_row = (pretty
                         .iloc[[np.argmax(pretty['PPMS'].values)]]
                         .to_dict('records')[0])
    equally_fast_binary = pretty[pretty['Binary PPMS'] > fastest_float_row['PPMS']]
    fast_binary_row = (equally_fast_binary
                       .iloc[[np.argmax(equally_fast_binary['Binary MRR'].values)]]
                       .to_dict('records')[0])

    print('As expected, for the same dimensionality a binary model '
          'achieves lower ranking accuracy. On average, the accuracy loss '
          'is around {:.0f}\%, varying between {:.0f}\% and {:.0f}\%.'.format(
              (1.0 - pretty['MRR ratio'].mean()) * 100,
              (1.0 - pretty['MRR ratio'].max()) * 100,
              (1.0 - pretty['MRR ratio'].min()) * 100))
    print('Nevertheless, the binary model\'s speed enables some very favourable tradeoffs')
    print('')
    print('When optimizing for MRR in both settings (at {} dimensions for the '
          'continuous and {} for the binary case), the XNOR representation achieves {:.0f}\% '
          'of the maximum MRR of the float '
          'representations at {:.0f} times the query throughput and using only '
          '{:.0f}\% of the memory.'.format(
              int(highest_float_mrr_row['Dimension']),
              int(highest_binary_mrr_row['Dimension']),
              (highest_binary_mrr_row['Binary MRR'] /
               highest_float_mrr_row['MRR'] * 100),
              (highest_binary_mrr_row['Binary PPMS']
               / highest_float_mrr_row['PPMS']),
              (highest_binary_mrr_row['Binary memory use']
               / highest_float_mrr_row['Memory use'] * 100),
          ))
    print('')
    print('When optimizing for query throughput at {} dimensions for '
          'the continuous case, the XNOR representation (at {} dimensions) '
          'can improve the ranking performance by achieving {:.0f}\% '
          'of the continuous MRR while being slightly faster at {:.1f} times '
          'the query throughput, and using {:.0f}\% of the memory.'.format(
              int(fastest_float_row['Dimension']),
              int(fast_binary_row['Dimension']),
              (fast_binary_row['Binary MRR'] /
               fastest_float_row['MRR'] * 100),
              fast_binary_row['Binary PPMS'] / fastest_float_row['PPMS'],
              (fast_binary_row['Binary memory use']
               / fastest_float_row['Memory use'] * 100)
          ))


@cli.command()
def plot():

    validation_db = Results('movielens_1M_validation.log')
    validation_db.plot('movielens.svg')


if __name__ == '__main__':
    cli(obj={})
